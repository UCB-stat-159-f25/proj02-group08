{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190671f6",
   "metadata": {},
   "source": [
    "# Project 2  Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb610bc",
   "metadata": {},
   "source": [
    "**Resources:**\n",
    "- LDA:\n",
    "    - https://medium.com/sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06 \n",
    "    - https://www.kaggle.com/code/faressayah/text-analysis-topic-modeling-with-spacy-gensim#%F0%9F%93%9A-Topic-Modeling (code for previous post)\n",
    "    - https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf/ \n",
    "- BERTopic:\n",
    "    - https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html#visualize-documents-with-plotly \n",
    "    - https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_topics.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8d5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## MOVE THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "####################\n",
    "## CALL THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from spacy import displacy\n",
    "from bertopic import BERTopic\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65c1e4f-4c8e-49b5-9b2f-c7ea55171e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## CALL THIS BLOCK FROM part00_utils_visuals.py\n",
    "####################\n",
    "\n",
    "# read in SOTU.csv using pandas, name the variable `sou` for simplicity\n",
    "# the below cell is what the output should look like\n",
    "\n",
    "from src import part00_utils_visuals as part00\n",
    "# import src.part00_utils_visuals as part00\n",
    "\n",
    "part00.plot_style(style=part00.PLOT_STYLE_SEABORN)\n",
    "\n",
    "sou = part00.pd.read_csv(part00.DIR_DATA_RAW / part00.CSV_SOTU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273fe096-f1b5-49bb-9f62-63e961a05187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4234f895-e020-4fad-b5e9-1a9711688877",
   "metadata": {},
   "source": [
    "sou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42c5f8",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "- Train an LDA model with 18 topics\n",
    "- Output the top 10 words for each topic. \n",
    "- Output the topic distribution for the first speech\n",
    "- Make a visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de433b",
   "metadata": {},
   "source": [
    "You may use the next two cells to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "febf5f1d-900f-4ce8-ae82-b8a36e398c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d4f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## MOVE THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "####################\n",
    "## CALL THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "def preprocess_text(text): \n",
    "    doc = nlp(text) \n",
    "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d189a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all texts - note this takes ~ 5 minutes to run\n",
    "processed_docs = sou['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f98993",
   "metadata": {},
   "source": [
    "To train an LDA model, use the LdaModel function that we imported a couple of cells back. The last resource linked under the LDA section is especially useful for walking through the steps we have below. *Note: one of the arguments to the LdaModel function is `random_state` which specifies the random seed for reproducibility. Please set yours to 42. Further, the last resource provided uses `LdaMulticore` which is essentially a parallelizable version of our function `LdaModel`. Use `LdaModel` instead, but the usage will be similar, except you can ignore the `iterations` and `workers` arguments..*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e83bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary from processed_docs, which is a list of tokens extracted from our speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LDA model with 18 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top 10 words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa52884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the topic distribution for the first speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a visualization using pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a289403",
   "metadata": {},
   "source": [
    "### BERTopic\n",
    "\n",
    "- Train a BERTopic model with a `min_topic_size` of 3 *Hint: use `BERTopic` to instantiate the model and specify `min_topic_size` in here. Actually fit the model using `fit_transform`, which `docs` passed into this.*\n",
    "- Output the top 10 words for each topic. \n",
    "- Output the topic distribution for the first speech\n",
    "- Make a visualization of the topics (see topic_model.visualize_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abebdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sou['Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model - this takes about 30 seconds\n",
    "\n",
    "# remove stop words from the topics (Hint: use CountVectorizer and then .update_topics on topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7775b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the top 10 words for each topic - hint see get_topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af432f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the topic distribution for the first speech\n",
    "# hint: check out approximate_distribution() and visualize_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to visualize the topics\n",
    "topic_model.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb:percent,py"
  },
  "kernelspec": {
   "display_name": "IPython - sotu",
   "language": "python",
   "name": "sotu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
