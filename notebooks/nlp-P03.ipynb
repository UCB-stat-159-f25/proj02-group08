{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190671f6",
   "metadata": {},
   "source": [
    "# Project 2  Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb610bc",
   "metadata": {},
   "source": [
    "**Resources:**\n",
    "- LDA:\n",
    "    - https://medium.com/sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06 \n",
    "    - https://www.kaggle.com/code/faressayah/text-analysis-topic-modeling-with-spacy-gensim#%F0%9F%93%9A-Topic-Modeling (code for previous post)\n",
    "    - https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf/ \n",
    "- BERTopic:\n",
    "    - https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html#visualize-documents-with-plotly \n",
    "    - https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_topics.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8d5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## MOVE THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "####################\n",
    "## CALL THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "from tqdm import tqdm\n",
    "from spacy import displacy\n",
    "from bertopic import BERTopic\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c65c1e4f-4c8e-49b5-9b2f-c7ea55171e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## CALL THIS BLOCK FROM part00_utils_visuals.py\n",
    "####################\n",
    "\n",
    "# read in SOTU.csv using pandas, name the variable `sou` for simplicity\n",
    "# the below cell is what the output should look like\n",
    "\n",
    "from src import part00_utils_visuals as part00\n",
    "# import src.part00_utils_visuals as part00\n",
    "\n",
    "part00.plot_style(style=part00.PLOT_STYLE_SEABORN)\n",
    "\n",
    "sou = part00.pd.read_csv(part00.DIR_DATA_RAW / part00.CSV_SOTU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c24cb6dc-ca34-4e60-84d7-ac5d2766d740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Year</th>\n",
       "      <th>Text</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>\\n[Before speaking, the President presented hi...</td>\n",
       "      <td>8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>\\nThe President. Mr. Speaker——\\n[At this point...</td>\n",
       "      <td>8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>\\nThe President. Thank you all very, very much...</td>\n",
       "      <td>7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>\\nThe President. Thank you. Thank you. Thank y...</td>\n",
       "      <td>7734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>\\nThe President. Thank you very much. Thank yo...</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>\\nFellow-Citizens of the Senate and House of R...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             President    Year  \\\n",
       "0      Joseph R. Biden  2024.0   \n",
       "1      Joseph R. Biden  2023.0   \n",
       "2      Joseph R. Biden  2022.0   \n",
       "3      Joseph R. Biden  2021.0   \n",
       "4      Donald J. Trump  2020.0   \n",
       "..                 ...     ...   \n",
       "241  George Washington  1791.0   \n",
       "242  George Washington  1790.0   \n",
       "243  George Washington  1790.0   \n",
       "244  George Washington  1790.0   \n",
       "245  George Washington  1790.0   \n",
       "\n",
       "                                                  Text  Word Count  \n",
       "0    \\n[Before speaking, the President presented hi...        8003  \n",
       "1    \\nThe President. Mr. Speaker——\\n[At this point...        8978  \n",
       "2    \\nThe President. Thank you all very, very much...        7539  \n",
       "3    \\nThe President. Thank you. Thank you. Thank y...        7734  \n",
       "4    \\nThe President. Thank you very much. Thank yo...        6169  \n",
       "..                                                 ...         ...  \n",
       "241  \\nFellow-Citizens of the Senate and House of R...        2264  \n",
       "242  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "243  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "244  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "245  \\nFellow-Citizens of the Senate and House of R...        1069  \n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42c5f8",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "- Train an LDA model with 18 topics\n",
    "- Output the top 10 words for each topic. \n",
    "- Output the topic distribution for the first speech\n",
    "- Make a visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de433b",
   "metadata": {},
   "source": [
    "You may use the next two cells to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "febf5f1d-900f-4ce8-ae82-b8a36e398c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d4f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## MOVE THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "####################\n",
    "## CALL THIS BLOCK TO part03.py\n",
    "####################\n",
    "\n",
    "def preprocess_text(text): \n",
    "    doc = nlp(text) \n",
    "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d189a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all texts - note this takes ~ 5 minutes to run\n",
    "processed_docs = sou['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f98993",
   "metadata": {},
   "source": [
    "To train an LDA model, use the LdaModel function that we imported a couple of cells back. The last resource linked under the LDA section is especially useful for walking through the steps we have below. *Note: one of the arguments to the LdaModel function is `random_state` which specifies the random seed for reproducibility. Please set yours to 42. Further, the last resource provided uses `LdaMulticore` which is essentially a parallelizable version of our function `LdaModel`. Use `LdaModel` instead, but the usage will be similar, except you can ignore the `iterations` and `workers` arguments..*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e83bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary from processed_docs, which is a list of tokens extracted from our speeches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LDA model with 18 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top 10 words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa52884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the topic distribution for the first speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a visualization using pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a289403",
   "metadata": {},
   "source": [
    "### BERTopic\n",
    "\n",
    "- Train a BERTopic model with a `min_topic_size` of 3 *Hint: use `BERTopic` to instantiate the model and specify `min_topic_size` in here. Actually fit the model using `fit_transform`, which `docs` passed into this.*\n",
    "- Output the top 10 words for each topic. \n",
    "- Output the topic distribution for the first speech\n",
    "- Make a visualization of the topics (see topic_model.visualize_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abebdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = sou['Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model - this takes about 30 seconds\n",
    "\n",
    "# remove stop words from the topics (Hint: use CountVectorizer and then .update_topics on topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7775b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the top 10 words for each topic - hint see get_topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af432f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the topic distribution for the first speech\n",
    "# hint: check out approximate_distribution() and visualize_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to visualize the topics\n",
    "topic_model.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb:percent,py"
  },
  "kernelspec": {
   "display_name": "IPython - sotu",
   "language": "python",
   "name": "sotu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
